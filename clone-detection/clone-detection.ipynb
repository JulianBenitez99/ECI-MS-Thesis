{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyPNeE1DajbFL6ukMGFaHjmW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-qIFr_cZLA5a","executionInfo":{"status":"ok","timestamp":1713309321640,"user_tz":300,"elapsed":5522,"user":{"displayName":"Julián Benítez Gutiérrez","userId":"01894930060764521238"}},"outputId":"d9589fd2-e095-4ad5-9ee1-1225855db69b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install torch transformers"]},{"cell_type":"code","source":["# Copyright (c) Microsoft Corporation.\n","# Licensed under the MIT license.\n","\n","import torch\n","import torch.nn as nn\n","from transformers import RobertaTokenizer, RobertaModel, RobertaConfig\n","\n","class UniXcoder(nn.Module):\n","    def __init__(self, model_name):\n","        \"\"\"\n","            Build UniXcoder.\n","\n","            Parameters:\n","\n","            * `model_name`- huggingface model card name. e.g. microsoft/unixcoder-base\n","        \"\"\"\n","        super(UniXcoder, self).__init__()\n","        self.tokenizer = RobertaTokenizer.from_pretrained(model_name)\n","        self.config = RobertaConfig.from_pretrained(model_name)\n","        self.config.is_decoder = True\n","        self.model = RobertaModel.from_pretrained(model_name, config=self.config)\n","\n","        self.register_buffer(\"bias\", torch.tril(torch.ones((1024, 1024), dtype=torch.uint8)).view(1,1024, 1024))\n","        self.lm_head = nn.Linear(self.config.hidden_size, self.config.vocab_size, bias=False)\n","        self.lm_head.weight = self.model.embeddings.word_embeddings.weight\n","        self.lsm = nn.LogSoftmax(dim=-1)\n","\n","        self.tokenizer.add_tokens([\"<mask0>\"],special_tokens=True)\n","\n","    def tokenize(self, inputs, mode=\"<encoder-only>\", max_length=512, padding=False):\n","        \"\"\"\n","        Convert string to token ids\n","\n","        Parameters:\n","\n","        * `inputs`- list of input strings.\n","        * `max_length`- The maximum total source sequence length after tokenization.\n","        * `padding`- whether to pad source sequence length to max_length.\n","        * `mode`- which mode the sequence will use. i.e. <encoder-only>, <decoder-only>, <encoder-decoder>\n","        \"\"\"\n","        assert mode in [\"<encoder-only>\", \"<decoder-only>\", \"<encoder-decoder>\"]\n","        assert max_length < 1024\n","\n","        tokenizer = self.tokenizer\n","\n","        tokens_ids = []\n","        for x in inputs:\n","            tokens = tokenizer.tokenize(x)\n","            if mode == \"<encoder-only>\":\n","                tokens = tokens[:max_length-4]\n","                tokens = [tokenizer.cls_token,mode,tokenizer.sep_token] + tokens + [tokenizer.sep_token]\n","            elif mode == \"<decoder-only>\":\n","                tokens = tokens[-(max_length-3):]\n","                tokens = [tokenizer.cls_token,mode,tokenizer.sep_token] + tokens\n","            else:\n","                tokens = tokens[:max_length-5]\n","                tokens = [tokenizer.cls_token,mode,tokenizer.sep_token] + tokens + [tokenizer.sep_token]\n","\n","            tokens_id = tokenizer.convert_tokens_to_ids(tokens)\n","            if padding:\n","                tokens_id = tokens_id + [self.config.pad_token_id] * (max_length-len(tokens_id))\n","            tokens_ids.append(tokens_id)\n","        return tokens_ids\n","\n","    def decode(self, source_ids):\n","        \"\"\" Convert token ids to string \"\"\"\n","        predictions = []\n","        for x in source_ids:\n","            prediction = []\n","            for y in x:\n","                t = y.cpu().numpy()\n","                t = list(t)\n","                if 0 in t:\n","                    t = t[:t.index(0)]\n","                text = self.tokenizer.decode(t,clean_up_tokenization_spaces=False)\n","                prediction.append(text)\n","            predictions.append(prediction)\n","        return predictions\n","\n","    def forward(self, source_ids):\n","        \"\"\" Obtain token embeddings and sentence embeddings \"\"\"\n","        mask = source_ids.ne(self.config.pad_token_id)\n","        token_embeddings = self.model(source_ids,attention_mask = mask.unsqueeze(1) * mask.unsqueeze(2))[0]\n","        sentence_embeddings = (token_embeddings * mask.unsqueeze(-1)).sum(1) / mask.sum(-1).unsqueeze(-1)\n","        return token_embeddings, sentence_embeddings\n","\n","    def generate(self, source_ids, decoder_only = True, eos_id = None, beam_size = 5, max_length = 64):\n","        \"\"\" Generate sequence given context (source_ids) \"\"\"\n","\n","        # Set encoder mask attention matrix: bidirectional for <encoder-decoder>, unirectional for <decoder-only>\n","        if decoder_only:\n","            mask = self.bias[:,:source_ids.size(-1),:source_ids.size(-1)]\n","        else:\n","            mask = source_ids.ne(self.config.pad_token_id)\n","            mask = mask.unsqueeze(1) * mask.unsqueeze(2)\n","\n","        if eos_id is None:\n","            eos_id = self.config.eos_token_id\n","\n","        device = source_ids.device\n","\n","        # Decoding using beam search\n","        preds = []\n","        zero = torch.LongTensor(1).fill_(0).to(device)\n","        source_len = list(source_ids.ne(1).sum(-1).cpu().numpy())\n","        length = source_ids.size(-1)\n","        encoder_output = self.model(source_ids,attention_mask=mask)\n","        for i in range(source_ids.shape[0]):\n","            context = [[x[i:i+1,:,:source_len[i]].repeat(beam_size,1,1,1) for x in y]\n","                     for y in encoder_output.past_key_values]\n","            beam = Beam(beam_size,eos_id,device)\n","            input_ids = beam.getCurrentState().clone()\n","            context_ids = source_ids[i:i+1,:source_len[i]].repeat(beam_size,1)\n","            out = encoder_output.last_hidden_state[i:i+1,:source_len[i]].repeat(beam_size,1,1)\n","            for _ in range(max_length):\n","                if beam.done():\n","                    break\n","                if _ == 0:\n","                    hidden_states = out[:,-1,:]\n","                    out = self.lsm(self.lm_head(hidden_states)).data\n","                    beam.advance(out)\n","                    input_ids.data.copy_(input_ids.data.index_select(0, beam.getCurrentOrigin()))\n","                    input_ids = beam.getCurrentState().clone()\n","                else:\n","                    length = context_ids.size(-1)+input_ids.size(-1)\n","                    out = self.model(input_ids,attention_mask=self.bias[:,context_ids.size(-1):length,:length],\n","                                       past_key_values=context).last_hidden_state\n","                    hidden_states = out[:,-1,:]\n","                    out = self.lsm(self.lm_head(hidden_states)).data\n","                    beam.advance(out)\n","                    input_ids.data.copy_(input_ids.data.index_select(0, beam.getCurrentOrigin()))\n","                    input_ids = torch.cat((input_ids,beam.getCurrentState().clone()),-1)\n","            hyp = beam.getHyp(beam.getFinal())\n","            pred = beam.buildTargetTokens(hyp)[:beam_size]\n","            pred = [torch.cat([x.view(-1) for x in p]+[zero]*(max_length-len(p))).view(1,-1) for p in pred]\n","            preds.append(torch.cat(pred,0).unsqueeze(0))\n","\n","        preds = torch.cat(preds,0)\n","\n","        return preds\n","\n","\n","\n","class Beam(object):\n","    def __init__(self, size, eos, device):\n","        self.size = size\n","        self.device = device\n","        # The score for each translation on the beam.\n","        self.scores = torch.FloatTensor(size).zero_().to(device)\n","        # The backpointers at each time-step.\n","        self.prevKs = []\n","        # The outputs at each time-step.\n","        self.nextYs = [torch.LongTensor(size).fill_(0).to(device)]\n","        # Has EOS topped the beam yet.\n","        self._eos = eos\n","        self.eosTop = False\n","        # Time and k pair for finished.\n","        self.finished = []\n","\n","    def getCurrentState(self):\n","        \"Get the outputs for the current timestep.\"\n","        batch = self.nextYs[-1].view(-1, 1)\n","        return batch\n","\n","    def getCurrentOrigin(self):\n","        \"Get the backpointers for the current timestep.\"\n","        return self.prevKs[-1]\n","\n","    def advance(self, wordLk):\n","        \"\"\"\n","        Given prob over words for every last beam `wordLk` and attention\n","        `attnOut`: Compute and update the beam search.\n","\n","        Parameters:\n","\n","        * `wordLk`- probs of advancing from the last step (K x words)\n","        * `attnOut`- attention at the last step\n","\n","        Returns: True if beam search is complete.\n","        \"\"\"\n","        numWords = wordLk.size(1)\n","\n","        # Sum the previous scores.\n","        if len(self.prevKs) > 0:\n","            beamLk = wordLk + self.scores.unsqueeze(1).expand_as(wordLk)\n","\n","            # Don't let EOS have children.\n","            for i in range(self.nextYs[-1].size(0)):\n","                if self.nextYs[-1][i] == self._eos:\n","                    beamLk[i] = -1e20\n","        else:\n","            beamLk = wordLk[0]\n","        flatBeamLk = beamLk.view(-1)\n","        bestScores, bestScoresId = flatBeamLk.topk(self.size, 0, True, True)\n","\n","        self.scores = bestScores\n","\n","        # bestScoresId is flattened beam x word array, so calculate which\n","        # word and beam each score came from\n","        prevK = torch.div(bestScoresId, numWords, rounding_mode=\"floor\")\n","        self.prevKs.append(prevK)\n","        self.nextYs.append((bestScoresId - prevK * numWords))\n","\n","\n","        for i in range(self.nextYs[-1].size(0)):\n","            if self.nextYs[-1][i] == self._eos:\n","                s = self.scores[i]\n","                self.finished.append((s, len(self.nextYs) - 1, i))\n","\n","        # End condition is when top-of-beam is EOS and no global score.\n","        if self.nextYs[-1][0] == self._eos:\n","            self.eosTop = True\n","\n","    def done(self):\n","        return self.eosTop and len(self.finished) >= self.size\n","\n","    def getFinal(self):\n","        if len(self.finished) == 0:\n","            self.finished.append((self.scores[0], len(self.nextYs) - 1, 0))\n","        self.finished.sort(key=lambda a: -a[0])\n","        if len(self.finished) != self.size:\n","            unfinished=[]\n","            for i in range(self.nextYs[-1].size(0)):\n","                if self.nextYs[-1][i] != self._eos:\n","                    s = self.scores[i]\n","                    unfinished.append((s, len(self.nextYs) - 1, i))\n","            unfinished.sort(key=lambda a: -a[0])\n","            self.finished+=unfinished[:self.size-len(self.finished)]\n","        return self.finished[:self.size]\n","\n","    def getHyp(self, beam_res):\n","        \"\"\"\n","        Walk back to construct the full hypothesis.\n","        \"\"\"\n","        hyps=[]\n","        for _,timestep, k in beam_res:\n","            hyp = []\n","            for j in range(len(self.prevKs[:timestep]) - 1, -1, -1):\n","                hyp.append(self.nextYs[j+1][k])\n","                k = self.prevKs[j][k]\n","            hyps.append(hyp[::-1])\n","        return hyps\n","\n","    def buildTargetTokens(self, preds):\n","        sentence=[]\n","        for pred in preds:\n","            tokens = []\n","            for tok in pred:\n","                if tok==self._eos:\n","                    break\n","                tokens.append(tok)\n","            sentence.append(tokens)\n","        return sentence\n"],"metadata":{"id":"S21WHFggLNJ6","executionInfo":{"status":"ok","timestamp":1713309341362,"user_tz":300,"elapsed":10567,"user":{"displayName":"Julián Benítez Gutiérrez","userId":"01894930060764521238"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = UniXcoder(\"Lazyhope/unixcoder-clone-detection\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NnuVpNZtMeEo","executionInfo":{"status":"ok","timestamp":1713309742029,"user_tz":300,"elapsed":1721,"user":{"displayName":"Julián Benítez Gutiérrez","userId":"01894930060764521238"}},"outputId":"1114f8ed-25b0-4497-f539-bfb6a46108a8"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["UniXcoder(\n","  (model): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(51416, 768, padding_idx=1)\n","      (position_embeddings): Embedding(1026, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(10, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51416, bias=False)\n","  (lsm): LogSoftmax(dim=-1)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["func = \"func sum(a, b int) int {return a+b}\"\n","# encode first function\n","tokens_ids = model.tokenize([func],max_length=512,mode=\"<encoder-only>\")\n","source_ids = torch.tensor(tokens_ids).to(device)\n","tokens_embeddings,f_func_embedding = model(source_ids)\n","\n","# which is actually another code\n","nl = \"func sayHello() {return \\\"hello!\\\"}\"\n","tokens_ids = model.tokenize([nl],max_length=512,mode=\"<encoder-only>\")\n","source_ids = torch.tensor(tokens_ids).to(device)\n","tokens_embeddings,nl_embedding = model(source_ids)\n","\n","norm_f_func_embedding = torch.nn.functional.normalize(f_func_embedding, p=2, dim=1)\n","norm_nl_embedding = torch.nn.functional.normalize(nl_embedding, p=2, dim=1)\n","\n","f_func_nl_similarity = torch.einsum(\"ac,bc->ab\",norm_f_func_embedding,norm_nl_embedding)\n","\n","print(f_func_embedding.shape)\n","print(f_func_embedding)\n","\n","print(f_func_nl_similarity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRCzrYlIM_2v","executionInfo":{"status":"ok","timestamp":1713309840024,"user_tz":300,"elapsed":299,"user":{"displayName":"Julián Benítez Gutiérrez","userId":"01894930060764521238"}},"outputId":"bf7606e4-63f6-4444-a0a6-b656cb5e1192"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 768])\n","tensor([[ 2.5775e+00, -7.1114e-01,  2.0317e+00,  4.1062e+00,  3.1691e+00,\n","         -1.7005e+00, -2.1389e-01, -2.3823e+00,  5.2817e+00,  5.2687e+00,\n","          6.7044e-01,  4.1625e-01,  5.8083e-01,  9.8646e-01,  9.0382e-01,\n","         -6.4011e-02,  4.0323e+00, -1.0631e+00,  1.6079e+00,  2.6012e+00,\n","         -6.4633e-01,  2.5105e+00, -3.8401e+00, -1.4461e-01, -4.0920e+00,\n","         -4.7729e-01,  2.9406e+00,  3.7135e+00, -1.7868e+00,  1.3972e+00,\n","         -7.3849e-01,  2.0992e+00,  2.3699e+00,  2.6714e+00, -6.9154e-01,\n","         -6.2210e-01,  2.9071e-01,  5.7066e-01, -1.1561e+00, -5.3467e+00,\n","         -1.8654e+00, -4.0399e-01,  1.9793e+00, -1.7453e+00,  1.7573e+00,\n","          6.8182e-02,  4.1310e+00,  1.7135e+00,  1.0264e+00,  1.8842e+00,\n","         -1.3644e+00,  9.4565e-01, -3.9716e-01, -3.9283e+00,  2.7915e-01,\n","         -5.7086e-01, -8.8920e-01, -3.9360e+00,  7.8825e-01, -2.5952e+00,\n","          2.7984e+00, -2.3213e-01, -1.0098e+00, -3.5498e+00, -8.9082e-01,\n","         -3.5001e-01,  8.0181e-01,  2.1060e+00,  3.0116e+00,  1.4948e+00,\n","          2.3607e-01,  1.6818e-01, -5.9072e+00,  4.2797e+00,  1.5262e+00,\n","          1.5929e+00, -3.3707e+00,  1.5767e+00,  4.9793e+00, -3.6996e-03,\n","         -4.4806e-01,  4.9010e-01, -6.0322e-01, -2.6389e+00,  1.5062e+00,\n","         -1.3083e+00,  4.0933e+00, -1.1230e+00,  2.5077e-01, -2.5243e+00,\n","          4.6698e-02, -5.2533e-01, -2.6365e+00,  3.4807e+00,  1.4793e-01,\n","          2.5038e+00,  7.7595e-01, -8.5429e-01, -1.0740e+00, -5.1403e+00,\n","          1.9212e+00, -7.3698e-01, -3.9579e+00, -1.3247e+00,  5.9673e-02,\n","          4.4323e+00, -1.2062e+00,  1.9551e-01,  2.9375e+00, -3.2431e+00,\n","          1.5002e-02,  4.3114e-01, -1.9029e+00,  1.9070e+00, -1.6312e+00,\n","         -8.6388e-01, -2.1049e+00, -1.8399e+00, -1.6818e+00, -1.7679e+00,\n","          3.0942e+00, -1.9385e+00,  2.3500e-01,  2.7940e-01, -4.4135e+00,\n","          1.9017e+00, -7.5019e-01, -6.4853e-01,  1.1600e+00, -1.6794e-01,\n","          9.1797e-01,  1.5447e+00, -3.8713e+00,  4.6085e-01, -1.1381e+00,\n","          4.5232e+00, -5.0602e-01,  9.5176e-01, -1.8702e+00, -2.8725e+00,\n","         -3.0841e+00, -1.0309e+00,  7.9286e-02,  2.7620e-01, -1.7005e+00,\n","         -1.0152e+00, -8.5082e-01,  9.6618e-01, -1.2121e-02,  2.2635e+00,\n","         -5.1312e+00, -2.2748e+00,  1.8930e-01, -3.6183e-01, -6.1284e-01,\n","         -2.7097e+00, -1.8278e-01, -1.9174e-01, -1.0496e+00, -2.4194e+00,\n","          6.1739e-01,  4.0942e-01,  9.1513e-02,  3.3398e-02,  1.0230e+00,\n","         -3.0771e+00,  2.1672e+00,  3.4504e+00, -1.3544e+00,  1.2268e+00,\n","         -2.0853e+00,  3.1068e+00,  2.4713e+00, -4.7508e-01, -1.7878e+00,\n","          2.9709e+00,  3.6781e+00,  1.6340e+00,  1.8717e+00,  2.3039e+00,\n","          1.5571e-01, -2.0563e-01, -2.0372e-02, -4.8710e-01,  2.9488e+00,\n","         -3.7946e+00,  1.9302e+00, -3.4508e-01, -4.3524e-01, -7.0047e-01,\n","          2.2152e+00,  3.2650e-01, -8.4077e-01,  2.0412e+00, -4.7088e-01,\n","          1.0515e+00,  1.5660e+00, -4.0717e-01, -1.1216e+00,  2.0076e+00,\n","          1.1041e+00, -4.7937e+00,  2.2210e+00, -1.8694e+00,  3.1467e-01,\n","          1.4365e+00, -1.3789e+00, -5.4769e+00,  1.2046e+00, -1.2406e+00,\n","         -4.1586e+00, -2.9785e+00,  3.4056e+00,  3.8820e+00, -2.6465e+00,\n","          3.4055e+00,  8.0333e-01, -1.2528e+00,  6.3911e-01, -3.9635e+00,\n","         -9.0367e-01, -2.3934e+00,  1.4717e+00,  1.9539e+00, -2.8194e+00,\n","          3.0993e+00,  5.1590e-01,  6.4724e-01,  1.2172e+00,  4.2857e-01,\n","         -8.3862e-01,  1.1770e-02,  2.0204e+00, -1.6709e+00,  2.2424e+00,\n","         -2.2282e+00,  8.2873e-01,  1.8525e+00, -2.6024e-02,  6.6077e-01,\n","         -7.2784e-01,  1.1644e+00, -2.9793e+00, -1.1814e+00,  2.6219e+00,\n","         -5.0805e-01,  9.4416e-01,  5.3666e-02,  1.5199e+00, -1.6071e+00,\n","          4.3227e-01,  2.2481e-01, -2.8941e+00,  1.7396e+00,  1.0166e+00,\n","         -2.9447e-02, -4.2134e-01, -3.6466e-01, -2.6684e-01,  1.4550e+00,\n","         -3.3145e-01, -2.3565e+00, -3.4868e+00,  1.9208e+00, -1.7389e+00,\n","         -3.2175e-01, -2.1870e+00, -8.1716e-01, -4.7418e-01, -9.1175e-01,\n","          1.0341e+00, -1.2929e+00, -2.9134e+00,  2.6385e-01, -3.3255e+00,\n","          1.2744e+00,  4.3140e-01, -2.9267e+00,  3.2859e-02,  1.8143e+00,\n","          7.0020e-01,  2.6042e+00, -1.5870e+00,  8.9356e-01,  5.3943e-01,\n","          6.8009e-01,  2.9617e+00,  1.5584e+00,  7.2766e+00,  3.0818e+00,\n","         -4.5489e-01, -5.6233e-01,  2.9182e+00, -1.5521e+00, -7.6783e-01,\n","         -3.3003e-01,  1.4503e+00,  1.0069e+00,  1.1362e+00,  3.2036e+00,\n","          1.4079e+00,  9.7994e-01, -1.9071e+00,  7.3466e-02,  3.6466e-03,\n","         -4.1204e-01,  2.1302e+00, -5.5461e-01, -8.7186e-01, -1.1210e+00,\n","          2.0506e+00, -1.3178e+00,  7.6064e-01,  2.4573e+00,  4.8779e-01,\n","         -8.9588e-01, -1.1928e+00, -1.4277e+00, -1.2427e+00, -6.6825e-01,\n","          5.0297e-01, -7.8500e-01, -5.4729e-01, -1.9077e+00,  2.3789e+00,\n","         -2.3396e-01,  3.6491e+00,  2.4434e-01,  1.1323e+00, -1.0266e+00,\n","         -1.1281e+00,  2.1992e+00, -2.8868e+00, -1.8254e+00,  2.2609e+00,\n","         -2.9456e+00,  1.0719e+00,  2.1138e+00, -1.8357e+00,  1.9549e+00,\n","         -2.3675e+00, -1.4402e+00, -3.3609e-01, -6.9002e-01,  1.7758e+00,\n","          1.2922e+00,  2.1863e+00, -6.7617e-01, -1.8168e+00,  2.3604e+00,\n","          2.2422e-01, -5.8560e-01,  1.6709e-01, -1.3691e+00, -4.7096e+00,\n","         -5.1157e-01, -2.9338e+00,  5.0803e-01, -1.8986e+00, -3.0366e-01,\n","         -3.9624e-02, -8.7250e-01,  6.6601e-01, -1.1648e+00, -1.7146e+00,\n","         -1.3623e-01, -1.0787e+00,  1.0893e+00,  2.2870e+00, -5.4173e+00,\n","          6.0183e-01, -1.7080e+00,  9.8638e-02, -2.6449e-01, -2.4140e-02,\n","         -4.4876e+00, -3.1569e+00,  1.6931e+00,  9.8799e-03, -1.4500e+00,\n","          6.0734e-01, -2.1054e+00, -1.7536e-01,  1.6357e+00,  1.8330e-01,\n","         -1.8252e+00,  8.4492e-01,  3.7664e+00,  2.9343e+00,  1.8964e+00,\n","          1.1974e-01,  6.3787e-01,  2.9260e+00,  8.6280e-01,  2.2826e+00,\n","          7.9818e-02,  3.2119e+00,  9.0577e-02, -1.6999e+00,  2.1005e+00,\n","         -1.2851e+00,  7.9872e-01, -2.8994e+00, -1.5600e+00,  1.4250e+00,\n","         -2.6892e+00, -2.0012e+00,  3.2132e+00,  1.3581e+00, -1.0223e+00,\n","         -2.6814e+00, -7.4924e-02,  3.1506e+00,  2.8150e-01, -9.8452e-01,\n","         -4.1530e-01,  3.7345e-01, -7.1368e-02,  8.8796e-01,  3.2516e+00,\n","          1.1192e+00,  4.8992e-01, -2.6456e-01, -8.5052e-02,  3.6910e+00,\n","          2.5019e-01, -2.0483e+00,  2.2107e+00, -9.2071e-01,  1.5467e-01,\n","         -3.8689e+00, -2.2702e+00, -6.3394e-01, -1.0218e+00,  1.1433e+00,\n","          1.3571e+00,  4.8952e-01, -1.8358e+00,  4.2469e-01,  8.2808e-01,\n","         -3.1344e+00, -7.6319e-01, -1.8740e+00,  2.2105e-01,  2.1620e+00,\n","          2.5547e+00, -1.0568e+00, -1.1823e+00, -1.3234e+00,  2.5109e+00,\n","         -1.1915e+00, -3.5923e-01, -3.4646e-01,  2.4312e+00,  6.8123e-01,\n","         -1.6227e+00,  3.9737e-01,  1.1686e+00, -1.9053e+00, -1.7633e+00,\n","          2.1513e+00,  4.8472e+00,  7.4020e-01, -2.7361e+00,  1.2918e+00,\n","          1.7777e+00, -2.1125e+00, -3.5296e-01, -2.6109e+00, -1.4911e-01,\n","         -2.2963e+00,  3.6154e+00, -5.8497e-01,  2.2155e+00, -7.2027e-01,\n","          1.8354e-01,  1.0959e+00, -1.2120e+00, -1.8850e+00,  2.2164e+00,\n","         -7.4380e-01,  1.1275e+00,  2.4053e+00,  1.8431e+00, -1.4444e+00,\n","          3.0278e+00, -1.9391e+00,  1.2669e+00, -2.4290e+00,  5.7420e-01,\n","          9.3821e-01,  3.2050e+00, -3.0177e-01, -3.4708e-01, -1.5366e+00,\n","         -3.8542e-02, -1.4027e+00, -1.2527e+00, -6.8021e-01,  3.1455e+00,\n","          9.9332e-01, -3.2844e+00,  5.5552e-02,  2.9549e+00,  3.1640e-01,\n","         -1.3600e+00, -2.3100e+00, -1.8753e+00,  2.7550e+00,  8.0811e-01,\n","         -2.5452e+00,  6.1963e-01,  2.4851e+00,  1.9389e+00, -1.4381e+00,\n","         -1.1646e+00,  2.3703e+00,  2.5445e+00, -7.5297e-01,  1.7273e+00,\n","         -4.7389e+00,  5.7707e-01,  1.0665e+00,  7.1480e-01,  1.1221e+00,\n","         -2.9386e-01, -5.1825e+00,  3.7820e+00,  1.5890e+00, -7.5515e-01,\n","          9.2264e+00,  1.1823e+00,  1.3555e+00, -1.3383e+00, -2.3469e+00,\n","         -2.5653e-02, -4.2072e-01,  1.4007e+00, -2.0051e-01, -1.6663e+00,\n","         -1.9112e+00, -4.1280e+00, -2.6029e+00, -1.8511e+00, -2.8316e+00,\n","          3.0868e+00, -3.1358e+00, -3.1375e+00,  3.5290e-01,  9.4699e-01,\n","         -4.5624e+00, -2.3466e+00,  1.5090e-01,  1.0432e+00, -8.2362e-01,\n","         -2.4334e-01, -2.9127e+00,  2.8407e-01,  8.4436e-01,  1.0378e+00,\n","         -1.2412e+00,  1.1906e+00, -1.4322e+00,  2.5736e+00,  2.1882e+00,\n","         -2.4590e+00,  1.1821e+00,  2.4309e-01, -9.9853e-01,  1.0646e+00,\n","         -1.7268e+00, -1.5822e+00, -2.0032e+00,  5.5862e-01,  4.2959e-01,\n","         -1.3270e+00,  2.0640e-01,  3.4318e+00, -1.5578e+00,  1.0331e+00,\n","         -1.8349e+00,  2.5672e+00, -6.9705e-01,  7.6247e-01, -5.9528e-01,\n","          1.0963e+00, -2.4341e+00,  3.3709e+00,  3.4061e+00,  3.0954e-01,\n","          3.0321e+00,  2.5012e+00, -3.8530e-02, -1.4011e+00,  2.7242e+00,\n","         -1.1041e-01,  2.0221e+00, -1.5238e+00, -2.3518e+00, -2.7878e+00,\n","          9.3955e-03, -6.5307e-01,  2.4132e+00,  1.4145e+00, -3.1708e-01,\n","         -9.7990e-01, -2.2381e-01,  1.7864e+00,  1.0160e+00, -2.6739e+00,\n","          1.0824e+00,  2.5222e-01, -6.7443e-01, -1.7036e+00,  1.7295e+00,\n","          1.9153e+00, -2.1809e+00,  2.8445e-02, -2.2900e+00, -1.0085e+00,\n","         -8.5631e-01,  2.4155e+00, -1.8025e-01, -2.7515e+00,  3.9836e+00,\n","          8.3675e-01,  3.3998e+00,  2.2963e+00,  1.8365e+00,  9.9233e-01,\n","         -2.0500e-03,  2.3576e+00, -3.0293e+00, -1.9233e+00,  1.1081e+00,\n","         -2.0273e+00,  4.3727e+00, -4.7111e-02,  1.9866e+00,  8.6945e-01,\n","         -1.8002e+00, -1.9438e-01, -3.4326e+00, -3.5476e-01, -8.1729e-03,\n","         -3.9338e-01, -3.6550e+00,  3.7130e+00,  7.4147e-03,  2.0925e+00,\n","         -1.3273e+00,  1.2677e+00,  3.9274e-01,  6.1440e-01, -2.7551e-01,\n","         -1.1295e+00, -1.0300e+00, -7.8072e-01, -3.6730e-01, -4.3341e+00,\n","         -2.1733e-01, -7.5378e-01,  3.5842e-01,  2.9607e+00,  1.4772e+00,\n","         -2.5071e+00,  8.8113e-01, -9.7648e-01, -1.4056e+00, -7.9655e-01,\n","          3.5772e+00, -1.0364e+00, -2.2392e-01, -1.3216e+00,  1.6937e+00,\n","          3.2377e+00, -1.9705e+00, -4.6214e-02,  6.4353e-01,  2.5808e+00,\n","          5.6693e-01,  3.1213e+00, -5.7576e-02,  4.1783e-01, -1.0692e+00,\n","         -1.1419e-01,  3.1960e+00, -2.5646e-01, -2.2272e+00,  3.6950e-01,\n","          1.6777e+00,  2.8244e+00,  2.3107e+00, -1.0905e-01,  3.9311e-01,\n","         -1.2827e+00, -1.1549e+00,  1.0288e+00,  1.5763e+00,  1.9131e+00,\n","          6.4125e-02, -1.1850e-01, -4.1241e+00,  3.3259e-01,  1.0308e+00,\n","         -1.9084e+00, -1.5711e+00, -5.1738e-01,  1.0516e+00, -1.6172e+00,\n","          2.0636e+00,  1.7621e+00, -5.8760e-01,  4.2961e-01,  8.1098e-01,\n","         -1.4250e+00,  2.2837e+00, -2.2409e+00,  2.2425e-01,  2.7480e+00,\n","          2.2270e+00,  1.9508e+00,  1.4240e+00, -2.0791e-02, -2.9489e-01,\n","          3.1696e+00,  7.7722e-01,  2.9103e+00,  2.5617e+00, -2.5231e-01,\n","          1.7878e+00,  2.7902e-01, -1.0531e+00,  1.2337e+00, -5.9226e-01,\n","          2.6119e+00, -1.7480e+00,  3.2577e+00,  1.6199e+00,  3.0716e-01,\n","         -2.4262e+00,  2.5808e+00,  4.0727e+00,  1.3241e+00,  2.8179e+00,\n","         -8.2423e-03,  1.0541e+00, -1.7883e+00, -7.4018e-01, -7.0012e-01,\n","          1.9292e+00,  8.9660e-01, -4.1953e-01, -1.9598e+00,  1.8942e+00,\n","          1.9607e-01, -3.7287e+00, -8.0754e-01, -9.1621e-01,  1.2086e+00,\n","          1.3827e+00,  3.4105e-01, -1.3757e+00, -1.6177e+00, -1.3627e+00,\n","         -9.0877e-01, -5.9521e+00,  1.8423e+00]], device='cuda:0',\n","       grad_fn=<DivBackward0>)\n","tensor([[0.0835]], device='cuda:0', grad_fn=<ViewBackward0>)\n"]}]}]}